<?xml version="1.0" encoding="UTF-8" ?>
<!-- **********************************************************************-->
<!-- Copyright 2012-2025                                                   -->
<!-- Matthew Boelkins                                                      -->
<!--                                                                       -->
<!-- This file is part of Active Calculus.                                 -->
<!--                                                                       -->
<!-- Permission is granted to copy, distribute and/or modify this document -->
<!-- under the terms of the Creative Commons BY-SA license.  The work      -->
<!-- may be used for free by any party so long as attribution is given to  -->
<!-- the author(s), the work and its derivatives are used in the spirit of -->
<!-- "share and share alike".  All trademarks are the registered marks of  -->
<!-- their respective owners.                                              -->
<!-- **********************************************************************-->

<section xmlns:xi="http://www.w3.org/2001/XInclude" xml:id="sec-8a-5x-accuracy-of-approx">
  <title>Quantifying the accuracy of approximations</title>
  <objectives>
    <ul>
      <li>
        <p>
          For an infinite series that converges, how much accuracy do we lose when we truncate the series after a finite number of terms to approximate its value with a finite sum?
        </p>
      </li>
      <li>
        <p>
          What is an alternating series and how can we determine whether or not it converges?  How do the partial sums of a converging alternating series accurately estimate its exact sum?
        </p>
      </li>
      <li>
        <p>
          What is the Lagrange Error Bound and how can we use it to understand how accurate a function's degree-<m>n</m> Taylor polynomial approximation is?
        </p>
      </li>
    </ul>

  </objectives>

  <introduction>
    <p>
      This section is all about understanding precisely how accurate certain approximations are.  Through Taylor series, we now know that we can represent certain functions and their values exactly through infinite sums.  For example, we know that for any value of <m>x</m>, 
      <me>
        e^x = 1 + x + \frac{1}{2!}x^2 + \frac{1}{3!}x^3 + \cdots + \frac{1}{n!}x^n + \cdots
      </me>
      so it follows that 
      <men xml:id="eq-8a-5x-exp-1-2">
        e^{-1/2} = 1 + \left(\frac{-1}{2}\right) + \frac{1}{2!} \left(\frac{-1}{2}\right)^2 + \cdots + \frac{1}{n!} \left(\frac{-1}{2}\right)^n + \cdots
      </men>. 
      If we decide to estimate the exact value of <m>e^{-1/2}</m> using the first <m>5</m> terms of this infinite sum, it turns out to be possible to use both the fact that we chose <q><m>5</m></q> and properties of <m>f(x) = e^x</m> to quantify the maximum error in the estimate
      <me>
        e^{-1/2} \approx 1 + \left(\frac{-1}{2}\right) + \frac{1}{2!} \left(\frac{-1}{2}\right)^2 + \frac{1}{3!} \left(\frac{-1}{2}\right)^3 + \frac{1}{4!} \left(\frac{-1}{2}\right)^4
      </me>.
    </p>

    <p>
      As we have seen, most of the infinite series that arise (such as the one in <xref ref="eq-8a-5x-exp-1-2">Equation</xref>) are not geometric.  But since geometric series are among the easiest infinite series to understand and evaluate, we use a geometric series as the starting point for our analysis of approximation errors.  In <xref ref="PA-8a-5x">Preview Activity</xref>, we investigate an example of a convergent geometric series and explore how we can use terms in the series itself to quantify how accurate a partial sum approximation is.
    </p>

  <!--  <xi:include href="./previews/PA-8a-5x-WW.xml" /> -->
  <xi:include href="./previews/PA-8a-5x.xml" /> 

  </introduction>  


  <subsection>
    <title>
      Alternating series of real numbers
    </title>

    <p>
      Next we consider the definite integral
      <me>
        \int_0^1 e^{-x^2} \, dx
      </me>,
      which is related to the well-known error function, <m>\erf(x)</m>.  
      While we are unable to find an elementary algebraic antiderivative of <m>e^{-x^2}</m>, if we use the Taylor series 
      <me>
        e^{-x^2} = 1 - x^2 + \frac{1}{2!}x^4 - \frac{1}{3!}x^6 + \cdots + (-1)^n \frac{1}{n!} x^{2n} + \cdots
      </me>
      and apply the Fundamental Theorem of Calculus to the series representation of <m>e^{-x^2}</m>, we find that
      <mdn>
        <mrow number="no">\int_0^1 e^{-x^2} \, dx =\mathstrut \amp \int_0^1 \left( 1 - x^2 + \frac{1}{2!}x^4 - \frac{1}{3!}x^6 + \cdots + (-1)^n \frac{1}{n!} x^{2n} + \cdots \right) \, dx</mrow>
        <mrow number="no"> =\mathstrut \amp \left. x - \frac{1}{3}x^3 + \frac{1}{5 \cdot 2!} x^5 + \cdots +  \frac{(-1)^n}{(2n+1) n!} x^{2n+1} + \cdots \right|_0^1 </mrow>
        <mrow number="no"> =\mathstrut \amp \left(1 - \frac{1}{3} + \frac{1}{5 \cdot 2!} + \cdots + \frac{(-1)^n}{(2n+1) n!} + \cdots \right) - \left( 0 \right)</mrow>
        <mrow xml:id="eq-8a-5x-alt-sum-ex2"> =\mathstrut \amp 1 - \frac{1}{3} + \frac{1}{5 \cdot 2!} - \frac{1}{7 \cdot 3!} + \cdots + \frac{(-1)^n}{(2n+1) n!} + \cdots</mrow>
      </mdn>   
      Like the geometric series <m>\sum_{k=0}^{\infty} (-1)^k \left( \frac{4}{5} \right)^k </m> that we encountered in <xref ref="PA-8a-5x">Preview Activity</xref>, the infinite series in <xref ref="eq-8a-5x-alt-sum-ex2">Equation</xref> is an example of an <term>alternating series</term> of real numbers.  It turns out to be straightforward to determine whether or not an alternating series converges and to estimate the value of a convergent alternating series. 
    </p>

    <definition>
      <statement>
        <p>
          An alternating series is a series of the form
          <me>
            \sum_{k=0}^{\infty} (-1)^k a_k
          </me>,
          where <m>a_k \gt 0</m> for each <m>k</m>.
        </p>
      </statement>
    </definition>

    <p>
      We will only consider alternating series for which the sequence of positive numbers <m>a_k</m> decreases to <m>0</m>.  The following example illustrates two general results that hold for any alternating series whose terms <m>a_k</m> decrease to <m>0</m>.  We use a geometric series so that we can know its exact sum and compare certain computations to that sum.
    </p>

    <p>
      In <xref ref="PA-8a-5x">Preview Activity</xref>, we investigated the partial sums of the convergent alternating geometric series <m>S = \sum_{k=0}^{\infty} (-1)^k \left( \frac{4}{5} \right)^k</m>, whose sum is <m>S = \fra{5}{9}</m>.  We found the first several partial sums shown in <xref ref="T-8a-5x-ExGeom"/>.  

      <table xml:id="T-8a-5x-ExGeom">
        <title>Partial sums of the alternating series <m>S = \sum_{k=0}^{\infty} (-1)^k \left( \frac{4}{5} \right)^k</m></title>
          <tabular top="minor" bottom="minor">
            <row>
              <cell halign="center"><m>n</m></cell>
              <cell><m>S_n</m></cell>
            </row>
            <row>
              <cell halign="center"><m>1</m></cell>
              <cell><m>1</m></cell>
            </row>  
            <row>  
              <cell halign="center"><m>2</m></cell>
              <cell><m>\frac{2}{5} = 0.2</m></cell>
            </row>
            <row>
              <cell halign="center"><m>3</m></cell>
              <cell><m>\frac{21}{25} = 0.84</m></cell>
            </row>
            <row>
              <cell halign="center"><m>4</m></cell>
              <cell><m>\frac{41}{125} = 0.328</m></cell>
            </row>
            <row>
              <cell halign="center"><m>5</m></cell>
              <cell><m>\frac{461}{625} = 0.7376</m></cell>
            </row>
            <row>
              <cell halign="center"><m>6</m></cell>
              <cell><m>\frac{1281}{3125} = 0.40992</m></cell>
            </row>
            <row>
              <cell halign="center"><m>7</m></cell>
              <cell><m>\frac{10501}{15625} = 0.672064</m></cell>
            </row>   
            <row>
              <cell halign="center"><m>8</m></cell>
              <cell><m>\frac{36121}{78125} = 0.4623488</m></cell>
            </row>
<!--        <row>
              <cell halign="center"><m>9</m></cell>
              <cell><m>\frac{246141}{390625} = 0.63012096</m></cell>               
            </row>           
            <row>                
              <cell halign="center"><m>10</m></cell>
              <cell><m>\frac{968561}{1953125} = 0.495903232</m></cell>
            </row>
-->              
            </tabular>
          </table>
        Plotting these partial sums in <xref ref="F-8a-5x-alt-partial-sums">Figure</xref>, we see an important pattern in how the partial sums approach the exact value of the infinite sum.
        <figure xml:id="F-8a-5x-alt-partial-sums">
          <caption>Plotting the partial sums <m>S_1</m>, <m>S_2</m>, <m>\ldots</m>, <m>S_8</m>.</caption>
            <image width="80%">
            <prefigure label="Fig-8a-5x-alt-partial-sums" xmlns="https://prefigure.org">  
              <diagram dimensions="(300,200)" margins="10">
                <definition>a = 3</definition> 
                <definition>p = (-0.25, 0.5555555555)</definition> 
                <definition>q = (9.5, 0.5555555555)</definition>   
                <coordinates bbox="(-1,-0.25,10,1.5)">
                  <axes hticks="(0,1,9)" vticks="(0,0.25,1.25)"/>
                  <line endpoints="(p, q)" stroke="blue" thickness="1.5" dash="4 4" infinite="no"/>     
                  <point p="(1,1)" alignment="n" scale="0.8" size="3.5">
                    <m>S_1</m>
                  </point>
                  <point p="(2,0.2)" alignment="w" scale="0.8" size="3.5">
                    <m>S_2</m>
                  </point>
                  <point p="(3,0.84)" alignment="n" scale="0.8" size="3.5">
                    <m>S_3</m>
                  </point>
                  <point p="(4,0.328)" alignment="s" scale="0.8" size="3.5">
                    <m>S_4</m>
                  </point>
                  <point p="(5,0.7376)" alignment="n" scale="0.8" size="3.5">
                    <m>S_5</m>
                  </point>  
                  <point p="(6,0.40922)" alignment="s" scale="0.8" size="3.5">
                    <m>S_6</m>
                  </point>   
                  <point p="(7,0.672064)" alignment="n" scale="0.8" size="3.5">
                    <m>S_7</m>
                  </point> 
                  <point p="(8,0.4623488)" alignment="s" scale="0.8" size="3.5">
                    <m>S_8</m>
                  </point>    
                </coordinates>
              </diagram>
            </prefigure>
          </image>    
        </figure>
          In both the table and the figure, we see how consecutive partial sums move back and forth above and below the exact sum of the infinite series, <m>\frac{5}{9}</m>, and moreover how the amount the next partial sum lies above or below <m>\frac{5}{9}</m> is less than the amount by which the previous partial sum deviated.  For instance, 
          <me>
            |S_5 - \frac{5}{9}| \approx 0.1820,
          </me>
          but 
          <me>
            |S_6 - \frac{5}{9}| \approx 0.1456
          </me>.
          Moreover, since <m>S_6 = S_5 - \left( \frac{4}{5} \right)^5</m>, and <m>-\left( \frac{4}{5} \right)^5 = -0.32768</m> is the last and smallest term (in absolute value) in <m>S_6</m>, <m>0.32768</m> is the total vertical distance from the point <m>(5, S_5)</m> to <m>(6, S_6)</m> in <xref ref="F-8a-5x-alt-partial-sums">Figure</xref>.  This implies that <m>0.32768</m> is more than the error in comparing <m>S_5</m> and <m>S</m>.  Said differently, we are guaranteed that
          <me>
            |S - S_5| \lt \left( \frac{4}{5} \right)^5
          </me>
          so the next term in the sum provides a bound on the error in a given partial sum.  A similar argument can be made for any value of <m>n</m>.
        </p>

    <p>  
      A more general version of this argument can be made for any alternating series whose terms go to zero.  This leads us to state two important results.
    </p>

    <assemblage>
      <title>The Alternating Series Test</title>
      <p>
        Given an alternating series
        <me>
        \sum_{k=0}^{\infty} (-1)^k a_k
        </me>,
        if the positive terms <m>a_k</m> decrease to 0 as <m>k \to \infty</m>,
        then the alternating series converges.
      </p>
    </assemblage>

    <p>
      If we were to compute the partial sums <m>S_n</m> of any alternating series whose terms decrease to zero and plot the points <m>(n,S_n)</m> as we did in <xref ref="F-8a-5x-alt-partial-sums">Figure</xref>, we would see a similar picture:  the partial sums alternate above and below the value to which the infinite alternating series converges.  In addition, because the terms go to zero, the amount a given partial sum deviates from the total sum is at most the next term in the series.  This result is formally stated as the Alternating Series Estimation Theorem.
    </p>

    <assemblage>
      <title>Alternating Series Estimation Theorem</title>
      <p>
        If the alternating series
        <m>
        \sum_{k=0}^{\infty} (-1)^{k}a_k
        </m>
        has positive terms <m>a_k</m> that decrease to zero as <m>k \to \infty</m>, and
        <m>
        S_n = \sum_{k=0}^{n-1} (-1)^{k}a_k
        </m>
        is the <m>n</m>th partial sum of the alternating series, then
        <me>
          \left| \sum_{k=0}^{\infty} (-1)^{k}a_k - S_n \right| \leq a_{n}
        </me>.
      </p>
    </assemblage>

    <p>
      Again, this result simply says: if we use a partial sum to estimate the exact sum of an alternating infinite series, the absolute error of the approximation is less than the next term in the series.
    </p>

    <example xml:id="Ex-8a-5x-ASET">
      <statement>
        <p>
          Determine how well the <m>100^{\mbox{th}}</m> partial sum <m>S_{100}</m> of
          <me>
            \sum_{k=0}^{\infty} \frac{(-1)^{k}}{k+1}
          </me>
          approximates the value of the converging alternating series.
        </p>
      </statement>
      <solution>
        <p>
          If we let <m>S</m> be the value of the series <m>\sum_{k=0}^{\infty} \frac{(-1)^{k}}{k+1}</m>,
          then we know that
          <me>
            \left| S_{100} - S \right| \lt  a_{100}
          </me>.
        </p>

        <p>
          Now
          <me>
            a_{100} = \frac{1}{101} \approx 0.0099
          </me>,
          so the <m>100^{\mbox{th}}</m> partial sum is within <m>0.0099</m> of the exact value of the series.  In addition, it turns out that <m>S_{100} \approx 0.688172</m> and <m>S = \ln(2) \approx 0.69314</m>, so we see that the difference between <m>S_{100}</m> and <m>S</m> is indeed less than the error bound of <m>0.0099</m> from the Alternating Series Estimation Theorem.
        </p>  
      </solution>
    </example>

    <xi:include href="./activities/act-8a-5x-1.xml" />

  </subsection>

  <subsection>
    <title>The Lagrange Error Bound</title>

    <p>
      See the following comment in the source for Steve's source on this to modify and update.  There will be exercises that can be used from his Section 8.5 as well in the original source.
    </p>

<!-- 
<subsection permid="AQC">
    <title>Error Approximations for Taylor Polynomials</title>
    <idx><h>Taylor polynomial</h><h>error</h></idx>

    <p permid="tAy">
      We now know how to find Taylor polynomials for functions such as <m>\sin(x)</m>,
      and how to determine the interval of convergence of the corresponding Taylor series.
      We next develop an error bound that will tell us how well an <m>n</m>th order Taylor polynomial <m>P_n(x)</m> approximates its generating function <m>f(x)</m>.
      This error bound will also allow us to determine whether a Taylor series on its interval of convergence actually equals the function <m>f</m> from which the Taylor series is derived.
      Finally, we will be able to use the error bound to determine the order of the Taylor polynomial <m>P_n(x)</m> that we will ensure that <m>P_n(x)</m> approximates <m>f(x)</m> to the desired degree of accuracy.
    </p>

    <p permid="ZHH">
      For this argument,
      we assume throughout that we center our approximations at <m>0</m>
      (but a similar argument holds for approximations centered at <m>a</m>).
      We define the exact error, <m>E_n(x)</m>,
      that results from approximating <m>f(x)</m> with <m>P_n(x)</m> by
      <me permid="ovg">
        E_n(x) = f(x) - P_n(x)
      </me>.
    </p>

    <p permid="FOQ">
      We are particularly interested in <m>|E_n(x)|</m>,
      the distance between <m>P_n</m> and <m>f</m>.
      Because
      <me permid="UCp">
        P^{(k)}_n(0) = f^{(k)}(0)
      </me>
      for <m>0 \leq k \leq n</m>, we know that
      <me permid="AJy">
        E^{(k)}_n(0) = 0
      </me>
      for <m>0 \leq k \leq n</m>.
      Furthermore,
      since <m>P_n(x)</m> is a polynomial of degree less than or equal to <m>n</m>,
      we know that
      <me permid="gQH">
        P_n^{(n+1)}(x) = 0
      </me>.
    </p>

    <p permid="lVZ">
      Thus, since <m>E^{(n+1)}_n(x) = f^{(n+1)}(x) - P_n^{(n+1)}(x)</m>,
      it follows that
      <me permid="MXQ">
        E^{(n+1)}_n(x) = f^{(n+1)}(x)
      </me>
      for all <m>x</m>.
    </p>

    <p permid="Sdi">
      Suppose that we want to approximate <m>f(x)</m> at a number <m>c</m> close to <m>0</m> using <m>P_n(c)</m>.
      If we assume <m>|f^{(n+1)}(t)|</m> is bounded by some number <m>M</m> on <m>[0, c]</m>, so that
      <me permid="teZ">
        \left|f^{(n+1)}(t)\right| \leq M
      </me>
      for all <m>0 \leq t \leq c</m>, then we can say that
      <me permid="Zmi">
        \left|E^{(n+1)}_n(t)\right| = \left|f^{(n+1)}(t)\right| \leq M
      </me>
      for all <m>t</m> between <m>0</m> and <m>c</m>.
      Equivalently,
      <men xml:id="E-ErrorIneq" permid="RHJ">
        -M \leq E^{(n+1)}_n(t) \leq M
      </men>
      on <m>[0, c]</m>.
      Next, we integrate the three terms in <xref ref="E-ErrorIneq">Inequality</xref>
      from <m>t = 0</m> to <m>t = x</m>, and thus find that
      <me permid="Ftr">
        \int_0^x -M \ dt \leq \int_0^x E^{(n+1)}_n(t) \ dt \leq \int_0^x M \ dt
      </me>
      for every value of <m>x</m> in <m>[0, c]</m>.
      Since <m>E^{(n)}_n(0) = 0</m>,
      the First FTC tells us that
      <me permid="lAA">
        -Mx \leq E^{(n)}_n(x) \leq Mx
      </me>
      for every <m>x</m> in <m>[0, c]</m>.
    </p>

    <p permid="ykr">
      Integrating this last inequality, we obtain
      <me permid="xOS">
        \int_0^x -Mt \ dt \leq \int_0^x E^{(n)}_n(t) \ dt \leq \int_0^x Mt \ dt
      </me>
      and thus
      <me permid="dWb">
        -M\frac{x^2}{2} \leq E^{(n-1)}_n(x) \leq M\frac{x^2}{2}
      </me>
      for all <m>x</m> in <m>[0, c]</m>.
    </p>

    <p permid="erA">
      Integrating <m>n</m> times, we arrive at
      <me permid="Kdk">
        -M\frac{x^{n+1}}{(n+1)!} \leq E_n(x) \leq M\frac{x^{n+1}}{(n+1)!}
      </me>
      for all <m>x</m> in <m>[0, c]</m>.
      This enables us to conclude that
      <me permid="qkt">
        \left|E_n(x)\right| \leq M\frac{|x|^{n+1}}{(n+1)!}
      </me>
      for all <m>x</m> in <m>[0, c]</m>,
      and we have found a bound on the approximation's error,
      <m>E_n</m>.
    </p>

    <p permid="KyJ">
      Our work above was based on the approximation centered at <m>a = 0</m>;
      the argument may be generalized to hold for any value of <m>a</m>,
      which results in the following theorem.
    </p>

    <assemblage permid="tmd">
      <title>The Lagrange Error Bound for <m>P_n(x)</m></title>
      <idx><h>Lagrange error bound</h></idx>

      <p permid="qFS">
        Let <m>f</m> be a continuous function with <m>n+1</m> continuous derivatives.
        Suppose that <m>M</m> is a positive real number such that
        <m>\left|f^{(n+1)}(x)\right| \le M</m> on the interval <m>[a, c]</m>.
        If <m>P_n(x)</m> is the <m>n</m>th order Taylor polynomial for <m>f(x)</m> centered at <m>x=a</m>, then
        <me permid="WrC">
          \left|P_n(c) - f(c)\right| \leq M\frac{|c-a|^{n+1}}{(n+1)!}
        </me>.
      </p>
    </assemblage>

    <p permid="WNb">
      We can use this error bound to tell us important information about Taylor polynomials and Taylor series,
      as we see in the following examples and activities.
    </p>

    <example xml:id="Ex-8-5-3" permid="Kko">
      <statement>
        <p permid="ogL">
          Determine how well the 10th order Taylor polynomial <m>P_{10}(x)</m> for <m>\sin(x)</m>,
          centered at <m>0</m>, approximates <m>\sin(2)</m>.
        </p>
      </statement>
      <solution permid="vbq">
        <p permid="rbr">
          To answer this question we use
          <m>f(x) = \sin(x)</m>, <m>c = 2</m>, <m>a=0</m>,
          and <m>n = 10</m> in the Lagrange error bound formula.
          We also need to find an appropriate value for <m>M</m>.
          Note that the derivatives of <m>f(x) = \sin(x)</m> are all equal to
          <m>\pm \sin(x)</m> or <m>\pm \cos(x)</m>.
          Thus,
          <me permid="CyL">
            \left| f^{(n+1)}(x) \right| \leq 1
          </me>
          for any <m>n</m> and <m>x</m>.
          Therefore, we can choose <m>M</m> to be <m>1</m>.
          Then
          <me permid="iFU">
            \left|P_{10}(2) - f(2)\right| \leq (1)\frac{|2-0|^{11}}{(11)!} = \frac{2^{11}}{(11)!} \approx 0.00005130671797
          </me>.
        </p>

        <p permid="XiA">
          So <m>P_{10}(2)</m> approximates <m>\sin(2)</m> to within at most <m>0.00005130671797</m>.
          A computer algebra system tells us that
          <me permid="ONd">
            P_{10}(2) \approx 0.9093474427 \ \ \text{ and }  \ \ \sin(2) \approx 0.9092974268
          </me>
          with an actual difference of about <m>0.0000500159</m>.
        </p>
      </solution>
    </example>

    <xi:include href="./activities/act-8-5-5.xml" />

    <example xml:id="Ex-8-5-4" permid="qrx">
      <statement>
        <p permid="UnU">
          Show that the Taylor series for <m>\sin(x)</m> actually converges to <m>\sin(x)</m> for all <m>x</m>.
        </p>
      </statement>
      <solution permid="biz">
        <p permid="DpJ">
          Recall from the previous example that since <m>f(x) = \sin(x)</m>, we know
          <me permid="uUm">
            \left| f^{(n+1)}(x) \right| \leq 1
          </me>
          for any <m>n</m> and <m>x</m>.
          This allows us to choose <m>M = 1</m> in the Lagrange error bound formula.
          Thus,
          <men xml:id="E-ErrorIneqSine" permid="bbv">
            |P_n(x) - \sin(x)| \leq \frac{|x|^{n+1}}{(n+1)!}
          </men>
          for every <m>x</m>.
        </p>

        <p permid="jwS">
          We showed in earlier work that the Taylor series
          <m>\sum_{k=0}^{\infty} \frac{x^k}{k!}</m> converges for every value of <m>x</m>.
          Because the terms of any convergent series must approach zero,
          it follows that
          <me permid="HiE">
            \lim_{n \to \infty} \frac{x^{n+1}}{(n+1)!} = 0
          </me>
          for every value of <m>x</m>.
          Thus, taking the limit as
          <m>n \to \infty</m> in the inequality<nbsp /><xref ref="E-ErrorIneqSine" />, it follows that
          <me permid="npN">
            \lim_{n \to \infty} |P_n(x) - \sin(x)| = 0
          </me>.
        </p>

        <p permid="PEb">
          As a result, we can now write
          <me permid="TwW">
            \sin(x) = \sum_{n=0}^{\infty} \frac{(-1)^nx^{2n+1}}{(2n+1)!}
          </me>
          for every real number <m>x</m>.
        </p>
      </solution>
    </example>

    <xi:include href="./activities/act-8-5-6.xml" />    
-->    

  </subsection>

  <subsection>
    <title>Summary</title>
    <p>
    <ul>
      <li>
        <p>
          An alternating series is one whose terms alternate in sign, often represented by <m>\sum_{k=0}^{\infty} (-1)^{k}a_k</m> where <m>a_k \gt 0</m> for all values of <m>k</m>.  Any alternating series whose terms <m>a_k</m> approach zero as <m>k \to \infty</m> is guaranteed to converge.  Moreover, the Alternating Series Estimation Theorem tells us that we can estimate the exact value of a converging alternating series by using a partial sum, and the error of that approximation is at most the next term in the series.  That is,
          <me>
            \left| \sum_{k=0}^{\infty} (-1)^{k}a_k - \left(a_0 - a_1 + a_2 - a_3 + \cdots + (-1)^{n-1} a_{n-1} \right) \right| \lt a_{n}
          </me>.
        </p>
      </li>
    </ul>
    </p>
  </subsection>

<xi:include href="./exercises/ez-8a-5x.xml" />

</section>
